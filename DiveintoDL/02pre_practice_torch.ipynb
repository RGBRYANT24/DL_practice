{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1 数据操作"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1.1入门"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import torch\r\n",
    "\r\n",
    "X = torch.arange(12)\r\n",
    "X.numel()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "X.reshape(3, 4)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#如果不能确定一个维度，可以用-1代替\r\n",
    "X.reshape(-1, 3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11]])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "标准差为1，均值为0的高斯正态分布"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "X = torch.randn(3, 4)\r\n",
    "X.mean(0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([ 0.0319,  0.3045, -0.3569,  0.6147])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import numpy as np\r\n",
    "torch.tensor(np.arange(12).reshape(3, 4))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]], dtype=torch.int32)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1.2运算"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "x = torch.tensor(np.arange(2, 10, 2))\r\n",
    "print(x)\r\n",
    "y = torch.tensor(np.ones(4) + 1)\r\n",
    "print(y)\r\n",
    "x + y, x / y, x ** y#这点就比tf好\r\n",
    "#tf还得搞数据类型转换 就离谱"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([2, 4, 6, 8], dtype=torch.int32)\n",
      "tensor([2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([ 4.,  6.,  8., 10.], dtype=torch.float64),\n",
       " tensor([1., 2., 3., 4.], dtype=torch.float64),\n",
       " tensor([ 4., 16., 36., 64.], dtype=torch.float64))"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "把多个张量连接在一起"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "X = torch.arange(12, dtype=torch.float32).reshape(-1, 4)\r\n",
    "print(X)\r\n",
    "Y = torch.tensor(np.arange(12).reshape(3, 4)[::-1, :].copy())\r\n",
    "print(Y)\r\n",
    "\r\n",
    "torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n",
      "tensor([[ 8,  9, 10, 11],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 0,  1,  2,  3]], dtype=torch.int32)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 0.,  1.,  2.,  3.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.,  8.,  9., 10., 11.],\n",
       "         [ 4.,  5.,  6.,  7.,  4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.,  0.,  1.,  2.,  3.]]))"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "print(X.sum())\r\n",
    "print(X.sum(0))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(66.)\n",
      "tensor([12., 15., 18., 21.])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1.3广播机制"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "a = torch.arange(3).reshape(3, 1)\r\n",
    "b = torch.arange(2).reshape(-1, 2)\r\n",
    "a, b"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2]]),\n",
       " tensor([[0, 1]]))"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "a + b"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3]])"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1.5节省内存\r\n",
    "如果进行Y = X + Y 的操作，那么Y指向的张量地址会发生变化（先回收原来的内存地址，然后分配计算完的新的内存地址，然后再让Y指向新的内存地址）\r\n",
    "可以使用原地操作，导致不用重新分配内存"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "before = id(Y)\r\n",
    "Y = Y + X\r\n",
    "before, id(Y)#可以看到先后内存地址不同"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2158702893880, 2158702866248)"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "Z = torch.zeros_like(Y)#创建一个形状和Y一样，但是数值全部为0的张量\r\n",
    "print(id(Z), Z)\r\n",
    "Z[:] = X +Y\r\n",
    "print(id(Z), Z)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2158702472792 tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "2158702472792 tensor([[ 8., 13., 18., 23.],\n",
      "        [20., 25., 30., 35.],\n",
      "        [32., 37., 42., 47.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1.6转换为其他Python对象"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "A = X.numpy()\r\n",
    "B = torch.tensor(A)\r\n",
    "type(A), type(B)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(numpy.ndarray, torch.Tensor)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "a = torch.tensor([3.5])\r\n",
    "a, a.item(), float(a), int(a)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([3.5000]), 3.5, 3.5, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 线性代数"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.3.1 标量\r\n",
    "- 标量只有一个数表示"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.3.4 张量\r\n",
    "- 提供描述具有任意数量轴的n维数组的通用方法\r\n",
    "- 向量是一阶张量，矩阵是二阶张量"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.3.5 张量算法的基本性质\r\n",
    "通过重新分配内存 clone 可以将A的一个副本分配给B\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "A= torch.arange(20, dtype=torch.float32).reshape(-1, 4)\r\n",
    "B = A.clone()\r\n",
    "A, A + B"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([[ 0.,  2.,  4.,  6.],\n",
       "         [ 8., 10., 12., 14.],\n",
       "         [16., 18., 20., 22.],\n",
       "         [24., 26., 28., 30.],\n",
       "         [32., 34., 36., 38.]]))"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.3.6降维\r\n",
    "通过对行和列分别求和，等价于对矩阵的所有元素进行求和"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "A.sum(axis=[0, 1])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(190.)"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "A.mean(), A.sum() / A.numel()#numel是元素个数"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor(9.5000), tensor(9.5000))"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "A.mean(axis=0), A.sum(axis=0) / A.shape[0]#shape是一个元组，列出了张量延每个轴的长度"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([ 8.,  9., 10., 11.]), tensor([ 8.,  9., 10., 11.]))"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2.3.6.1 非降维求和\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "sum_A = A.sum(axis=1, keepdims=True)#求和之后仍然保持两个轴\r\n",
    "sum_A, A.sum(axis=1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[ 6.],\n",
       "         [22.],\n",
       "         [38.],\n",
       "         [54.],\n",
       "         [70.]]),\n",
       " tensor([ 6., 22., 38., 54., 70.]))"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "A / sum_A #可以通过广播相除"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1667, 0.3333, 0.5000],\n",
       "        [0.1818, 0.2273, 0.2727, 0.3182],\n",
       "        [0.2105, 0.2368, 0.2632, 0.2895],\n",
       "        [0.2222, 0.2407, 0.2593, 0.2778],\n",
       "        [0.2286, 0.2429, 0.2571, 0.2714]])"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.3.7 点积\r\n",
    "点积是相同位置的元素按位置相乘的和"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "y = torch.ones(4, dtype=torch.float32)\r\n",
    "x = torch.arange(4, dtype=torch.float32)\r\n",
    "x, y, torch.dot(x, y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "也可以通过元素乘法，然后求和"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "torch.sum(x * y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.3.8 矩阵 向量积\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "A.shape, x.shape, torch.mv(A, x)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([5, 4]), torch.Size([4]), tensor([ 14.,  38.,  62.,  86., 110.]))"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.3.9 矩阵乘法"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "B = torch.ones(4, 3)\r\n",
    "torch.mm(A, B)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 6.,  6.,  6.],\n",
       "        [22., 22., 22.],\n",
       "        [38., 38., 38.],\n",
       "        [54., 54., 54.],\n",
       "        [70., 70., 70.]])"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.3.10 范数"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "u = torch.arange(3, 5, dtype=torch.float32)\r\n",
    "torch.norm(u)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.5 自动求导"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "\r\n",
    "x = torch.arange(4.0)\r\n",
    "x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "x.requires_grad_(True)\r\n",
    "x.grad"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "y = 2 * torch.dot(x, x)#矩阵对应位相乘\r\n",
    "y"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(28., grad_fn=<MulBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "调用反向传播函数自动计算y关于x每个分量的梯度。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "y.backward()\r\n",
    "x.grad"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "函数y=2x²的梯度应该是4x"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "x.grad == 4 * x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "#在默认情况下，pytorch会累积梯度，要清除之前的值\r\n",
    "x.grad.zero_()\r\n",
    "y = x.sum()\r\n",
    "y.backward()\r\n",
    "x.grad"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.5.2 非标量变量的反向传播\r\n",
    "当y不是标量的时候，向量y关于向量x的导数是一个矩阵。\r\n",
    "对于高阶和高维的y和x，求导的结果可以是一个高阶张量\r\n",
    "这里计算的不是微分矩阵，而是批量中每个样本单独计算的偏导数之和"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "x.grad.zero_()\r\n",
    "y = x * x \r\n",
    "y.sum().backward()\r\n",
    "x.grad"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "x.grad.zero_()\r\n",
    "y = x * x \r\n",
    "u = y.detach()#截断反向传播的梯度流\r\n",
    "z = u * x\r\n",
    "\r\n",
    "\r\n",
    "z.sum().backward()\r\n",
    "x.grad == u\r\n",
    "print(y.requires_grad)\r\n",
    "x.grad"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0., 1., 4., 9.])"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "x.grad.zero_()\r\n",
    "y.sum().backward()\r\n",
    "x.grad == 2 * x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 练习5 画出sin(x) 和导数的图像"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "#x = torch.tensor(torch.linspace(0, np.pi/2, 20))\r\n",
    "x = np.linspace(0, 2 * np.pi, 100)\r\n",
    "x1 = torch.tensor(x)\r\n",
    "x1.requires_grad_(True)\r\n",
    "y1 = torch.sin(x1)\r\n",
    "y1.sum().backward()\r\n",
    "plt.plot(x1.detach().numpy(), x1.grad.detach().numpy())\r\n",
    "plt.plot(x1.detach().numpy(), y1.detach().numpy())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2c519b70988>]"
      ]
     },
     "metadata": {},
     "execution_count": 77
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 386.845312 248.518125\" width=\"386.845312pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-08-10T00:52:12.967575</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 248.518125 \r\nL 386.845312 248.518125 \r\nL 386.845312 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 44.845313 224.64 \r\nL 379.645313 224.64 \r\nL 379.645313 7.2 \r\nL 44.845313 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m41e71c6bc4\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"60.063494\" xlink:href=\"#m41e71c6bc4\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(56.882244 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 2034 4250 \r\nQ 1547 4250 1301 3770 \r\nQ 1056 3291 1056 2328 \r\nQ 1056 1369 1301 889 \r\nQ 1547 409 2034 409 \r\nQ 2525 409 2770 889 \r\nQ 3016 1369 3016 2328 \r\nQ 3016 3291 2770 3770 \r\nQ 2525 4250 2034 4250 \r\nz\r\nM 2034 4750 \r\nQ 2819 4750 3233 4129 \r\nQ 3647 3509 3647 2328 \r\nQ 3647 1150 3233 529 \r\nQ 2819 -91 2034 -91 \r\nQ 1250 -91 836 529 \r\nQ 422 1150 422 2328 \r\nQ 422 3509 836 4129 \r\nQ 1250 4750 2034 4750 \r\nz\r\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.504472\" xlink:href=\"#m41e71c6bc4\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 1 -->\r\n      <g transform=\"translate(105.323222 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 794 531 \r\nL 1825 531 \r\nL 1825 4091 \r\nL 703 3866 \r\nL 703 4441 \r\nL 1819 4666 \r\nL 2450 4666 \r\nL 2450 531 \r\nL 3481 531 \r\nL 3481 0 \r\nL 794 0 \r\nL 794 531 \r\nz\r\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"156.945449\" xlink:href=\"#m41e71c6bc4\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 2 -->\r\n      <g transform=\"translate(153.764199 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 1228 531 \r\nL 3431 531 \r\nL 3431 0 \r\nL 469 0 \r\nL 469 531 \r\nQ 828 903 1448 1529 \r\nQ 2069 2156 2228 2338 \r\nQ 2531 2678 2651 2914 \r\nQ 2772 3150 2772 3378 \r\nQ 2772 3750 2511 3984 \r\nQ 2250 4219 1831 4219 \r\nQ 1534 4219 1204 4116 \r\nQ 875 4013 500 3803 \r\nL 500 4441 \r\nQ 881 4594 1212 4672 \r\nQ 1544 4750 1819 4750 \r\nQ 2544 4750 2975 4387 \r\nQ 3406 4025 3406 3419 \r\nQ 3406 3131 3298 2873 \r\nQ 3191 2616 2906 2266 \r\nQ 2828 2175 2409 1742 \r\nQ 1991 1309 1228 531 \r\nz\r\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-32\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"205.386426\" xlink:href=\"#m41e71c6bc4\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 3 -->\r\n      <g transform=\"translate(202.205176 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 2597 2516 \r\nQ 3050 2419 3304 2112 \r\nQ 3559 1806 3559 1356 \r\nQ 3559 666 3084 287 \r\nQ 2609 -91 1734 -91 \r\nQ 1441 -91 1130 -33 \r\nQ 819 25 488 141 \r\nL 488 750 \r\nQ 750 597 1062 519 \r\nQ 1375 441 1716 441 \r\nQ 2309 441 2620 675 \r\nQ 2931 909 2931 1356 \r\nQ 2931 1769 2642 2001 \r\nQ 2353 2234 1838 2234 \r\nL 1294 2234 \r\nL 1294 2753 \r\nL 1863 2753 \r\nQ 2328 2753 2575 2939 \r\nQ 2822 3125 2822 3475 \r\nQ 2822 3834 2567 4026 \r\nQ 2313 4219 1838 4219 \r\nQ 1578 4219 1281 4162 \r\nQ 984 4106 628 3988 \r\nL 628 4550 \r\nQ 988 4650 1302 4700 \r\nQ 1616 4750 1894 4750 \r\nQ 2613 4750 3031 4423 \r\nQ 3450 4097 3450 3541 \r\nQ 3450 3153 3228 2886 \r\nQ 3006 2619 2597 2516 \r\nz\r\n\" id=\"DejaVuSans-33\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-33\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"253.827403\" xlink:href=\"#m41e71c6bc4\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 4 -->\r\n      <g transform=\"translate(250.646153 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 2419 4116 \r\nL 825 1625 \r\nL 2419 1625 \r\nL 2419 4116 \r\nz\r\nM 2253 4666 \r\nL 3047 4666 \r\nL 3047 1625 \r\nL 3713 1625 \r\nL 3713 1100 \r\nL 3047 1100 \r\nL 3047 0 \r\nL 2419 0 \r\nL 2419 1100 \r\nL 313 1100 \r\nL 313 1709 \r\nL 2253 4666 \r\nz\r\n\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-34\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.26838\" xlink:href=\"#m41e71c6bc4\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(299.08713 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 691 4666 \r\nL 3169 4666 \r\nL 3169 4134 \r\nL 1269 4134 \r\nL 1269 2991 \r\nQ 1406 3038 1543 3061 \r\nQ 1681 3084 1819 3084 \r\nQ 2600 3084 3056 2656 \r\nQ 3513 2228 3513 1497 \r\nQ 3513 744 3044 326 \r\nQ 2575 -91 1722 -91 \r\nQ 1428 -91 1123 -41 \r\nQ 819 9 494 109 \r\nL 494 744 \r\nQ 775 591 1075 516 \r\nQ 1375 441 1709 441 \r\nQ 2250 441 2565 725 \r\nQ 2881 1009 2881 1497 \r\nQ 2881 1984 2565 2268 \r\nQ 2250 2553 1709 2553 \r\nQ 1456 2553 1204 2497 \r\nQ 953 2441 691 2322 \r\nL 691 4666 \r\nz\r\n\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"350.709358\" xlink:href=\"#m41e71c6bc4\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 6 -->\r\n      <g transform=\"translate(347.528108 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 2113 2584 \r\nQ 1688 2584 1439 2293 \r\nQ 1191 2003 1191 1497 \r\nQ 1191 994 1439 701 \r\nQ 1688 409 2113 409 \r\nQ 2538 409 2786 701 \r\nQ 3034 994 3034 1497 \r\nQ 3034 2003 2786 2293 \r\nQ 2538 2584 2113 2584 \r\nz\r\nM 3366 4563 \r\nL 3366 3988 \r\nQ 3128 4100 2886 4159 \r\nQ 2644 4219 2406 4219 \r\nQ 1781 4219 1451 3797 \r\nQ 1122 3375 1075 2522 \r\nQ 1259 2794 1537 2939 \r\nQ 1816 3084 2150 3084 \r\nQ 2853 3084 3261 2657 \r\nQ 3669 2231 3669 1497 \r\nQ 3669 778 3244 343 \r\nQ 2819 -91 2113 -91 \r\nQ 1303 -91 875 529 \r\nQ 447 1150 447 2328 \r\nQ 447 3434 972 4092 \r\nQ 1497 4750 2381 4750 \r\nQ 2619 4750 2861 4703 \r\nQ 3103 4656 3366 4563 \r\nz\r\n\" id=\"DejaVuSans-36\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-36\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_8\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"mc9dd184c90\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#mc9dd184c90\" y=\"214.768805\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- −1.00 -->\r\n      <g transform=\"translate(7.2 218.568024)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 678 2272 \r\nL 4684 2272 \r\nL 4684 1741 \r\nL 678 1741 \r\nL 678 2272 \r\nz\r\n\" id=\"DejaVuSans-2212\" transform=\"scale(0.015625)\"/>\r\n        <path d=\"M 684 794 \r\nL 1344 794 \r\nL 1344 0 \r\nL 684 0 \r\nL 684 794 \r\nz\r\n\" id=\"DejaVuSans-2e\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-2212\"/>\r\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-2e\"/>\r\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#mc9dd184c90\" y=\"190.058159\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- −0.75 -->\r\n      <g transform=\"translate(7.2 193.857378)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 525 4666 \r\nL 3525 4666 \r\nL 3525 4397 \r\nL 1831 0 \r\nL 1172 0 \r\nL 2766 4134 \r\nL 525 4134 \r\nL 525 4666 \r\nz\r\n\" id=\"DejaVuSans-37\" transform=\"scale(0.015625)\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-2212\"/>\r\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-2e\"/>\r\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-37\"/>\r\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#mc9dd184c90\" y=\"165.347513\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- −0.50 -->\r\n      <g transform=\"translate(7.2 169.146732)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-2212\"/>\r\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-2e\"/>\r\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-35\"/>\r\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#mc9dd184c90\" y=\"140.636867\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- −0.25 -->\r\n      <g transform=\"translate(7.2 144.436086)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-2212\"/>\r\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-2e\"/>\r\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"242.822266\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#mc9dd184c90\" y=\"115.926221\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 0.00 -->\r\n      <g transform=\"translate(15.579688 119.72544)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#mc9dd184c90\" y=\"91.215575\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 0.25 -->\r\n      <g transform=\"translate(15.579688 95.014793)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-32\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#mc9dd184c90\" y=\"66.504929\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 0.50 -->\r\n      <g transform=\"translate(15.579688 70.304147)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-35\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_15\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#mc9dd184c90\" y=\"41.794282\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 0.75 -->\r\n      <g transform=\"translate(15.579688 45.593501)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-37\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-35\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_9\">\r\n     <g id=\"line2d_16\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"44.845313\" xlink:href=\"#mc9dd184c90\" y=\"17.083636\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_16\">\r\n      <!-- 1.00 -->\r\n      <g transform=\"translate(15.579688 20.882855)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-31\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-30\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_17\">\r\n    <path clip-path=\"url(#p06cc6ea989)\" d=\"M 60.063494 17.083636 \r\nL 63.137874 17.282638 \r\nL 66.212255 17.878843 \r\nL 69.286635 18.869851 \r\nL 72.361015 20.25167 \r\nL 75.435395 22.018736 \r\nL 78.509775 24.163935 \r\nL 81.584155 26.678628 \r\nL 84.658536 29.55269 \r\nL 87.732916 32.774547 \r\nL 90.807296 36.331227 \r\nL 93.881676 40.208408 \r\nL 96.956056 44.390478 \r\nL 100.030436 48.860597 \r\nL 103.104817 53.600766 \r\nL 106.179197 58.591897 \r\nL 109.253577 63.813893 \r\nL 112.327957 69.245727 \r\nL 115.402337 74.865527 \r\nL 118.476717 80.650664 \r\nL 121.551098 86.577844 \r\nL 124.625478 92.623198 \r\nL 127.699858 98.762386 \r\nL 130.774238 104.970687 \r\nL 133.848618 111.223101 \r\nL 136.922998 117.494454 \r\nL 139.997379 123.759491 \r\nL 143.071759 129.992987 \r\nL 146.146139 136.169841 \r\nL 149.220519 142.265181 \r\nL 152.294899 148.254464 \r\nL 155.369279 154.113571 \r\nL 158.44366 159.818912 \r\nL 161.51804 165.347513 \r\nL 164.59242 170.677111 \r\nL 167.6668 175.786247 \r\nL 170.74118 180.654348 \r\nL 173.81556 185.261812 \r\nL 176.889941 189.590085 \r\nL 179.964321 193.62174 \r\nL 183.038701 197.340543 \r\nL 186.113081 200.731519 \r\nL 189.187461 203.781014 \r\nL 192.261841 206.476748 \r\nL 195.336222 208.807868 \r\nL 198.410602 210.764986 \r\nL 201.484982 212.340222 \r\nL 204.559362 213.527232 \r\nL 207.633742 214.321238 \r\nL 210.708122 214.719042 \r\nL 213.782503 214.719042 \r\nL 216.856883 214.321238 \r\nL 219.931263 213.527232 \r\nL 223.005643 212.340222 \r\nL 226.080023 210.764986 \r\nL 229.154403 208.807868 \r\nL 232.228784 206.476748 \r\nL 235.303164 203.781014 \r\nL 238.377544 200.731519 \r\nL 241.451924 197.340543 \r\nL 244.526304 193.62174 \r\nL 247.600684 189.590085 \r\nL 250.675065 185.261812 \r\nL 253.749445 180.654348 \r\nL 256.823825 175.786247 \r\nL 259.898205 170.677111 \r\nL 262.972585 165.347513 \r\nL 266.046965 159.818912 \r\nL 269.121346 154.113571 \r\nL 272.195726 148.254464 \r\nL 275.270106 142.265181 \r\nL 278.344486 136.169841 \r\nL 281.418866 129.992987 \r\nL 284.493246 123.759491 \r\nL 287.567627 117.494454 \r\nL 290.642007 111.223101 \r\nL 293.716387 104.970687 \r\nL 296.790767 98.762386 \r\nL 299.865147 92.623198 \r\nL 302.939527 86.577844 \r\nL 306.013908 80.650664 \r\nL 309.088288 74.865527 \r\nL 312.162668 69.245727 \r\nL 315.237048 63.813893 \r\nL 318.311428 58.591897 \r\nL 321.385808 53.600766 \r\nL 324.460189 48.860597 \r\nL 327.534569 44.390478 \r\nL 330.608949 40.208408 \r\nL 333.683329 36.331227 \r\nL 336.757709 32.774547 \r\nL 339.832089 29.55269 \r\nL 342.90647 26.678628 \r\nL 345.98085 24.163935 \r\nL 349.05523 22.018736 \r\nL 352.12961 20.25167 \r\nL 355.20399 18.869851 \r\nL 358.27837 17.878843 \r\nL 361.352751 17.282638 \r\nL 364.427131 17.083636 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_18\">\r\n    <path clip-path=\"url(#p06cc6ea989)\" d=\"M 60.063494 115.926221 \r\nL 63.137874 109.657237 \r\nL 66.212255 103.413495 \r\nL 69.286635 97.220139 \r\nL 72.361015 91.102105 \r\nL 75.435395 85.084029 \r\nL 78.509775 79.190143 \r\nL 81.584155 73.444181 \r\nL 84.658536 67.869279 \r\nL 87.732916 62.487885 \r\nL 90.807296 57.321669 \r\nL 93.881676 52.391432 \r\nL 96.956056 47.717028 \r\nL 100.030436 43.317278 \r\nL 103.104817 39.209898 \r\nL 106.179197 35.411428 \r\nL 109.253577 31.937163 \r\nL 112.327957 28.801092 \r\nL 115.402337 26.015843 \r\nL 118.476717 23.592632 \r\nL 121.551098 21.541215 \r\nL 124.625478 19.869854 \r\nL 127.699858 18.585277 \r\nL 130.774238 17.692658 \r\nL 133.848618 17.195591 \r\nL 136.922998 17.096078 \r\nL 139.997379 17.394518 \r\nL 143.071759 18.089711 \r\nL 146.146139 19.178857 \r\nL 149.220519 20.657571 \r\nL 152.294899 22.519898 \r\nL 155.369279 24.758339 \r\nL 158.44366 27.363881 \r\nL 161.51804 30.326032 \r\nL 164.59242 33.632865 \r\nL 167.6668 37.271064 \r\nL 170.74118 41.22598 \r\nL 173.81556 45.481687 \r\nL 176.889941 50.02105 \r\nL 179.964321 54.825789 \r\nL 183.038701 59.876558 \r\nL 186.113081 65.15302 \r\nL 189.187461 70.633927 \r\nL 192.261841 76.29721 \r\nL 195.336222 82.120066 \r\nL 198.410602 88.079047 \r\nL 201.484982 94.150158 \r\nL 204.559362 100.308954 \r\nL 207.633742 106.530636 \r\nL 210.708122 112.79015 \r\nL 213.782503 119.062292 \r\nL 216.856883 125.321806 \r\nL 219.931263 131.543487 \r\nL 223.005643 137.702283 \r\nL 226.080023 143.773395 \r\nL 229.154403 149.732376 \r\nL 232.228784 155.555231 \r\nL 235.303164 161.218514 \r\nL 238.377544 166.699422 \r\nL 241.451924 171.975883 \r\nL 244.526304 177.026653 \r\nL 247.600684 181.831392 \r\nL 250.675065 186.370755 \r\nL 253.749445 190.626462 \r\nL 256.823825 194.581378 \r\nL 259.898205 198.219577 \r\nL 262.972585 201.52641 \r\nL 266.046965 204.488561 \r\nL 269.121346 207.094103 \r\nL 272.195726 209.332544 \r\nL 275.270106 211.194871 \r\nL 278.344486 212.673584 \r\nL 281.418866 213.76273 \r\nL 284.493246 214.457923 \r\nL 287.567627 214.756364 \r\nL 290.642007 214.65685 \r\nL 293.716387 214.159783 \r\nL 296.790767 213.267164 \r\nL 299.865147 211.982588 \r\nL 302.939527 210.311226 \r\nL 306.013908 208.25981 \r\nL 309.088288 205.836598 \r\nL 312.162668 203.051349 \r\nL 315.237048 199.915278 \r\nL 318.311428 196.441013 \r\nL 321.385808 192.642543 \r\nL 324.460189 188.535164 \r\nL 327.534569 184.135414 \r\nL 330.608949 179.461009 \r\nL 333.683329 174.530773 \r\nL 336.757709 169.364556 \r\nL 339.832089 163.983163 \r\nL 342.90647 158.408261 \r\nL 345.98085 152.662298 \r\nL 349.05523 146.768413 \r\nL 352.12961 140.750337 \r\nL 355.20399 134.632303 \r\nL 358.27837 128.438946 \r\nL 361.352751 122.195205 \r\nL 364.427131 115.926221 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 44.845313 224.64 \r\nL 44.845313 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 379.645313 224.64 \r\nL 379.645313 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 44.845313 224.64 \r\nL 379.645313 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 44.845313 7.2 \r\nL 379.645313 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p06cc6ea989\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"44.845313\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "import torch\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "x = torch.arange(0.0,10.0,0.1)\r\n",
    "x.requires_grad_(True)\r\n",
    "x1 = x.detach()\r\n",
    "y1 = torch.sin(x1)\r\n",
    "y2 = torch.sin(x)\r\n",
    "y2.sum().backward()\r\n",
    "plt.plot(x1,y1)\r\n",
    "plt.plot(x1,x.grad)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved variables after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved variables after calling backward.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19756/2453995507.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0my2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0my2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0my3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved variables after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved variables after calling backward."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6ddfb83b3bc8c92edabdc3e93e5c4c6338b18a29ac03b8c349b7596e5c53e5d2"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('torch': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}